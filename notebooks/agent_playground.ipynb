{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "from datetime import datetime\n",
    "from typing import Optional\n",
    "from uuid import uuid4\n",
    "\n",
    "import pixeltable as pxt\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "class BaseAgent(ABC):\n",
    "    \"\"\"\n",
    "    An Base agent powered by LLM model with persistent memory and tool execution capabilities.\n",
    "\n",
    "    This base agent gets inherited by other agent classes (see pixelagent/anthropic/agent.py and pixelagent/anthropic/agent.py).\n",
    "\n",
    "    The agent maintains three key tables in Pixeltable:\n",
    "    1. memory: Stores all conversation history with timestamps\n",
    "    2. agent: Manages chat interactions and responses\n",
    "    3. tools: (Optional) Handles tool execution and responses\n",
    "\n",
    "    Key Features:\n",
    "    - Persistent conversation memory with optional message limit\n",
    "    - Tool execution support\n",
    "    - Structured data storage and orchestration using Pixeltable\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        name: str,\n",
    "        system_prompt: str,\n",
    "        model: str,\n",
    "        n_latest_messages: Optional[int] = 10,\n",
    "        tools: Optional[pxt.tools] = None,\n",
    "        reset: bool = False,\n",
    "        chat_kwargs: Optional[dict] = None,\n",
    "        tool_kwargs: Optional[dict] = None,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize the agent with the specified configuration.\n",
    "\n",
    "        Args:\n",
    "            name: Unique name for the agent (used for table names)\n",
    "            system_prompt: System prompt that guides LLM's behavior\n",
    "            model: LLM model to use\n",
    "            n_latest_messages: Number of recent messages to include in context (None for unlimited)\n",
    "            tools: Optional tools configuration for function calling\n",
    "            reset: If True, deletes existing agent data\n",
    "            chat_kwargs: Additional kwargs for chat completion\n",
    "            tool_kwargs: Additional kwargs for tool execution\n",
    "        \"\"\"\n",
    "        self.directory = name\n",
    "        self.system_prompt = system_prompt\n",
    "        self.model = model\n",
    "        self.n_latest_messages = n_latest_messages\n",
    "        self.tools = tools\n",
    "        self.chat_kwargs = chat_kwargs or {}\n",
    "        self.tool_kwargs = tool_kwargs or {}\n",
    "\n",
    "        # Set up or reset the agent's database\n",
    "        if reset:\n",
    "            pxt.drop_dir(self.directory, if_not_exists=\"ignore\", force=True)\n",
    "\n",
    "        # Create agent directory if it doesn't exist\n",
    "        pxt.create_dir(self.directory, if_exists=\"ignore\")\n",
    "\n",
    "        # Set up tables\n",
    "        self._setup_tables()\n",
    "\n",
    "        # Get references to the created tables\n",
    "        self.memory = pxt.get_table(f\"{self.directory}.memory\")\n",
    "        self.agent = pxt.get_table(f\"{self.directory}.agent\")\n",
    "        self.tools_table = (\n",
    "            pxt.get_table(f\"{self.directory}.tools\") if self.tools else None\n",
    "        )\n",
    "\n",
    "    def _setup_tables(self):\n",
    "        \"\"\"\n",
    "        Initialize the required Pixeltable tables for the agent.\n",
    "        Creates three tables:\n",
    "        1. memory: Stores conversation history\n",
    "        2. agent: Manages chat completions\n",
    "        3. tools: (Optional) Handles tool execution\n",
    "        \"\"\"\n",
    "        # Create memory table for conversation history\n",
    "        self.memory = pxt.create_table(\n",
    "            f\"{self.directory}.memory\",\n",
    "            {\n",
    "                \"message_id\": pxt.String,  # Unique ID for each message\n",
    "                \"role\": pxt.String,  # 'user' or 'assistant'\n",
    "                \"content\": pxt.String,  # Message content\n",
    "                \"timestamp\": pxt.Timestamp,  # When the message was received\n",
    "            },\n",
    "            if_exists=\"ignore\",\n",
    "        )\n",
    "\n",
    "        # Create agent table for managing chat interactions\n",
    "        self.agent = pxt.create_table(\n",
    "            f\"{self.directory}.agent\",\n",
    "            {\n",
    "                \"message_id\": pxt.String,  # Unique ID for each message\n",
    "                \"user_message\": pxt.String,  # User's message content\n",
    "                \"timestamp\": pxt.Timestamp,  # When the message was received\n",
    "                \"system_prompt\": pxt.String,  # System prompt for Claude\n",
    "                \"image\": pxt.Image,  # Optional image attachment\n",
    "            },\n",
    "            if_exists=\"ignore\",\n",
    "        )\n",
    "\n",
    "        # Create tools table if tools are configured\n",
    "        if self.tools:\n",
    "            self.tools_table = pxt.create_table(\n",
    "                f\"{self.directory}.tools\",\n",
    "                {\n",
    "                    \"tool_invoke_id\": pxt.String,  # Unique ID for each tool invocation\n",
    "                    \"tool_prompt\": pxt.String,  # Tool prompt for Claude\n",
    "                    \"timestamp\": pxt.Timestamp,  # When the tool was invoked\n",
    "                },\n",
    "                if_exists=\"ignore\",\n",
    "            )\n",
    "            # Set up tools pipeline\n",
    "            self._setup_tools_pipeline()\n",
    "\n",
    "        # Set up chat pipeline\n",
    "        self._setup_chat_pipeline()\n",
    "\n",
    "    @abstractmethod\n",
    "    def _setup_chat_pipeline(self):\n",
    "        \"\"\"To be implemented by subclasses\"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    @abstractmethod\n",
    "    def _setup_tools_pipeline(self):\n",
    "        \"\"\"To be implemented by subclasses\"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def chat(self, message: str, image: Optional[Image.Image] = None) -> str:\n",
    "        \"\"\"\n",
    "        Send a message to the agent and get its response.\n",
    "\n",
    "        This method:\n",
    "        1. Stores the user message in memory\n",
    "        2. Triggers the chat completion pipeline\n",
    "        3. Stores the assistant's response in memory\n",
    "        4. Returns the response\n",
    "\n",
    "        Args:\n",
    "            message: The user's message\n",
    "\n",
    "        Returns:\n",
    "            The agent's response\n",
    "        \"\"\"\n",
    "        now = datetime.now()\n",
    "\n",
    "        # Generate unique IDs for the message pair\n",
    "        user_message_id = str(uuid4())\n",
    "        assistant_message_id = str(uuid4())\n",
    "\n",
    "        # Store user message in memory\n",
    "        self.memory.insert(\n",
    "            [\n",
    "                {\n",
    "                    \"message_id\": user_message_id,\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": message,\n",
    "                    \"timestamp\": now,\n",
    "                }\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # Store user message in agent table (which triggers the chat pipeline)\n",
    "        self.agent.insert(\n",
    "            [\n",
    "                {\n",
    "                    \"message_id\": user_message_id,\n",
    "                    \"user_message\": message,\n",
    "                    \"timestamp\": now,\n",
    "                    \"system_prompt\": self.system_prompt,\n",
    "                    \"image\": image,\n",
    "                }\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # Get LLM's response from agent table\n",
    "        result = (\n",
    "            self.agent.select(self.agent.agent_response)\n",
    "            .where(self.agent.message_id == user_message_id)\n",
    "            .collect()\n",
    "        )\n",
    "        response = result[\"agent_response\"][0]\n",
    "\n",
    "        # Store LLM's response in memory\n",
    "        self.memory.insert(\n",
    "            [\n",
    "                {\n",
    "                    \"message_id\": assistant_message_id,\n",
    "                    \"role\": \"assistant\",\n",
    "                    \"content\": response,\n",
    "                    \"timestamp\": now,\n",
    "                }\n",
    "            ]\n",
    "        )\n",
    "        return response\n",
    "\n",
    "    def tool_call(self, prompt: str) -> str:\n",
    "        \"\"\"\n",
    "        Execute a tool call with the given prompt.\n",
    "\n",
    "        This method:\n",
    "        1. Stores the user prompt in memory\n",
    "        2. Triggers the tool call handshake pipeline\n",
    "        3. Stores the tool's response in memory\n",
    "        4. Returns the response\n",
    "\n",
    "        Args:\n",
    "            prompt: The user's prompt\n",
    "\n",
    "        Returns:\n",
    "            The tool's response\n",
    "        \"\"\"\n",
    "        if not self.tools:\n",
    "            return \"No tools configured for this agent.\"\n",
    "\n",
    "        now = datetime.now()\n",
    "        user_message_id = str(uuid4())\n",
    "        tool_invoke_id = str(uuid4())\n",
    "        assistant_message_id = str(uuid4())\n",
    "\n",
    "        # Store user message in memory\n",
    "        self.memory.insert(\n",
    "            [\n",
    "                {\n",
    "                    \"message_id\": user_message_id,\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": prompt,\n",
    "                    \"timestamp\": now,\n",
    "                }\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # Store user prompt in tools table (which triggers the tool call handshake pipeline)\n",
    "        self.tools_table.insert(\n",
    "            [\n",
    "                {\n",
    "                    \"tool_invoke_id\": tool_invoke_id,\n",
    "                    \"tool_prompt\": prompt,\n",
    "                    \"timestamp\": now,\n",
    "                }\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # Get tool answer from tools table\n",
    "        result = (\n",
    "            self.tools_table.select(self.tools_table.tool_answer)\n",
    "            .where(self.tools_table.tool_invoke_id == tool_invoke_id)\n",
    "            .collect()\n",
    "        )\n",
    "        tool_answer = result[\"tool_answer\"][0]\n",
    "\n",
    "        # Store LLM's response in memory\n",
    "        self.memory.insert(\n",
    "            [\n",
    "                {\n",
    "                    \"message_id\": assistant_message_id,\n",
    "                    \"role\": \"assistant\",\n",
    "                    \"content\": tool_answer,\n",
    "                    \"timestamp\": now,\n",
    "                }\n",
    "            ]\n",
    "        )\n",
    "        return tool_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "import pixeltable as pxt\n",
    "import pixeltable.functions as pxtf\n",
    "\n",
    "try:\n",
    "    from pixeltable.functions.openai import chat_completions, invoke_tools\n",
    "except ImportError:\n",
    "    raise ImportError(\"openai not found; run `pip install openai`\")\n",
    "\n",
    "import base64\n",
    "import io\n",
    "from typing import Optional\n",
    "\n",
    "import PIL\n",
    "import pixeltable as pxt\n",
    "\n",
    "\n",
    "@pxt.udf\n",
    "def create_messages(\n",
    "    system_prompt: str,\n",
    "    memory_context: list[dict],\n",
    "    current_message: str,\n",
    "    image: Optional[PIL.Image.Image] = None,\n",
    ") -> list[dict]:\n",
    "\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt}]\n",
    "    messages.extend(memory_context.copy())\n",
    "\n",
    "    if not image:\n",
    "        messages.append({\"role\": \"user\", \"content\": current_message})\n",
    "        return messages\n",
    "\n",
    "    # Encode Image\n",
    "    bytes_arr = io.BytesIO()\n",
    "    image.save(bytes_arr, format=\"jpeg\")\n",
    "    b64_bytes = base64.b64encode(bytes_arr.getvalue())\n",
    "    b64_encoded_image = b64_bytes.decode(\"utf-8\")\n",
    "\n",
    "    # Create content blocks with text and image\n",
    "    content_blocks = [\n",
    "        {\"type\": \"text\", \"text\": current_message},\n",
    "        {\n",
    "            \"type\": \"image_url\",\n",
    "            \"image_url\": {\"url\": f\"data:image/jpeg;base64,{b64_encoded_image}\"},\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    messages.append({\"role\": \"user\", \"content\": content_blocks})\n",
    "    return messages\n",
    "\n",
    "class Agent(BaseAgent):\n",
    "    \"\"\"\n",
    "    OpenAI-specific implementation of the BaseAgent.\n",
    "\n",
    "    This agent uses OpenAI's chat completion API for generating responses and handling tools.\n",
    "    It inherits common functionality from BaseAgent including:\n",
    "    - Table setup and management\n",
    "    - Memory persistence\n",
    "    - Base chat and tool call implementations\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        name: str,\n",
    "        system_prompt: str,\n",
    "        model: str = \"gpt-4o-mini\",\n",
    "        n_latest_messages: Optional[int] = 10,\n",
    "        tools: Optional[pxt.tools] = None,\n",
    "        reset: bool = False,\n",
    "        chat_kwargs: Optional[dict] = None,\n",
    "        tool_kwargs: Optional[dict] = None,\n",
    "    ):\n",
    "        # Initialize the base agent with all common parameters\n",
    "        super().__init__(\n",
    "            name=name,\n",
    "            system_prompt=system_prompt,\n",
    "            model=model,\n",
    "            n_latest_messages=n_latest_messages,  # None for unlimited history\n",
    "            tools=tools,\n",
    "            reset=reset,\n",
    "            chat_kwargs=chat_kwargs,\n",
    "            tool_kwargs=tool_kwargs,\n",
    "        )\n",
    "\n",
    "    def _setup_chat_pipeline(self):\n",
    "        \"\"\"\n",
    "        Configure the chat completion pipeline using Pixeltable's computed columns.\n",
    "        This method implements the abstract method from BaseAgent.\n",
    "\n",
    "        The pipeline consists of 4 steps:\n",
    "        1. Retrieve recent messages from memory\n",
    "        2. Format messages with system prompt\n",
    "        3. Get completion from OpenAI\n",
    "        4. Extract the response text\n",
    "        \"\"\"\n",
    "\n",
    "        # Step 1: Define a query to get recent messages\n",
    "        @pxt.query\n",
    "        def get_recent_memory(current_timestamp: pxt.Timestamp) -> list[dict]:\n",
    "            \"\"\"\n",
    "            Get recent messages from memory, respecting n_latest_messages limit if set.\n",
    "            Messages are ordered by timestamp (newest first).\n",
    "            \"\"\"\n",
    "            query = (\n",
    "                self.memory.where(self.memory.timestamp < current_timestamp)\n",
    "                .order_by(self.memory.timestamp, asc=False)\n",
    "                .select(role=self.memory.role, content=self.memory.content)\n",
    "            )\n",
    "            if self.n_latest_messages is not None:\n",
    "                query = query.limit(self.n_latest_messages)\n",
    "            return query\n",
    "\n",
    "        # Step 2: Add computed columns to process the conversation\n",
    "        # First, get the conversation history\n",
    "        self.agent.add_computed_column(\n",
    "            memory_context=get_recent_memory(self.agent.timestamp),\n",
    "            if_exists=\"ignore\",\n",
    "        )\n",
    "\n",
    "        # Format messages for OpenAI with system prompt\n",
    "        self.agent.add_computed_column(\n",
    "            prompt=create_messages(\n",
    "                self.agent.system_prompt,\n",
    "                self.agent.memory_context,\n",
    "                self.agent.user_message,\n",
    "                self.agent.image,\n",
    "            ),\n",
    "            if_exists=\"ignore\",\n",
    "        )\n",
    "\n",
    "        # Get OpenAI's API response\n",
    "        self.agent.add_computed_column(\n",
    "            response=chat_completions(\n",
    "                messages=self.agent.prompt, model=self.model, **self.chat_kwargs\n",
    "            ),\n",
    "            if_exists=\"ignore\",\n",
    "        )\n",
    "\n",
    "        # Extract the final response text\n",
    "        self.agent.add_computed_column(\n",
    "            agent_response=self.agent.response.choices[0].message.content,\n",
    "            if_exists=\"ignore\",\n",
    "        )\n",
    "\n",
    "    def _setup_tools_pipeline(self):\n",
    "        \"\"\"\n",
    "        Configure the tool execution pipeline using Pixeltable's computed columns.\n",
    "        This method implements the abstract method from BaseAgent.\n",
    "\n",
    "        The pipeline has 4 stages:\n",
    "        1. Get initial response from OpenAI with potential tool calls\n",
    "        2. Execute any requested tools\n",
    "        3. Format tool results for follow-up\n",
    "        4. Get final response incorporating tool outputs\n",
    "        \"\"\"\n",
    "        # Stage 1: Get initial response with potential tool calls\n",
    "        self.tools_table.add_computed_column(\n",
    "            initial_response=chat_completions(\n",
    "                model=self.model,\n",
    "                messages=[{\"role\": \"user\", \"content\": self.tools_table.tool_prompt}],\n",
    "                tools=self.tools,  # Pass available tools to OpenAI\n",
    "                **self.tool_kwargs,\n",
    "            ),\n",
    "            if_exists=\"ignore\",\n",
    "        )\n",
    "\n",
    "        # Stage 2: Execute any tools that OpenAI requested\n",
    "        self.tools_table.add_computed_column(\n",
    "            tool_output=invoke_tools(self.tools, self.tools_table.initial_response),\n",
    "            if_exists=\"ignore\",\n",
    "        )\n",
    "\n",
    "        # Stage 3: Format tool results for follow-up\n",
    "        self.tools_table.add_computed_column(\n",
    "            tool_response_prompt=pxtf.string.format(\n",
    "                \"{0}: {1}\", self.tools_table.tool_prompt, self.tools_table.tool_output\n",
    "            ),\n",
    "            if_exists=\"ignore\",\n",
    "        )\n",
    "\n",
    "        # Stage 4: Get final response incorporating tool results\n",
    "        self.tools_table.add_computed_column(\n",
    "            final_response=chat_completions(\n",
    "                model=self.model,\n",
    "                messages=[\n",
    "                    {\"role\": \"user\", \"content\": self.tools_table.tool_response_prompt},\n",
    "                ],\n",
    "                **self.tool_kwargs,\n",
    "            ),\n",
    "            if_exists=\"ignore\",\n",
    "        )\n",
    "\n",
    "        # Extract the final response text\n",
    "        self.tools_table.add_computed_column(\n",
    "            tool_answer=self.tools_table.final_response.choices[0].message.content,\n",
    "            if_exists=\"ignore\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a Pixeltable instance at: /Users/moteroperdido/.pixeltable\n",
      "Connected to Pixeltable database at: postgresql+psycopg://postgres:@/pixeltable?host=/Users/moteroperdido/.pixeltable/pgdata\n",
      "Created directory 'my_assistant'.\n",
      "Created table `memory`.\n",
      "Created table `agent`.\n",
      "Added 0 column values with 0 errors.\n",
      "Added 0 column values with 0 errors.\n",
      "Added 0 column values with 0 errors.\n",
      "Added 0 column values with 0 errors.\n"
     ]
    }
   ],
   "source": [
    "agent = Agent(\n",
    "    name=\"my_assistant\",\n",
    "    system_prompt=\"You are a helpful assistant.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserting rows into `memory`: 1 rows [00:00, 22.91 rows/s]\n",
      "Inserted 1 row with 0 errors.\n"
     ]
    },
    {
     "ename": "Error",
     "evalue": "Exception in task: \nTraceback (most recent call last):\n  File \"/Users/moteroperdido/Desktop/projects/the_neural_maze/projects/multimodal-agents-course/.venv/lib/python3.12/site-packages/pixeltable/exec/expr_eval/schedulers.py\", line 190, in _exec\n    result = await pxt_fn.aexec(*request.args, **request.kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/moteroperdido/Desktop/projects/the_neural_maze/projects/multimodal-agents-course/.venv/lib/python3.12/site-packages/pixeltable/func/callable_function.py\", line 84, in aexec\n    return await self.py_fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/moteroperdido/Desktop/projects/the_neural_maze/projects/multimodal-agents-course/.venv/lib/python3.12/site-packages/pixeltable/functions/openai.py\", line 446, in chat_completions\n    rate_limits_info = env.Env.get().get_resource_pool_info(\n                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/moteroperdido/Desktop/projects/the_neural_maze/projects/multimodal-agents-course/.venv/lib/python3.12/site-packages/pixeltable/env.py\", line 705, in get_resource_pool_info\n    info = make_pool_info()\n           ^^^^^^^^^^^^^^^^\n  File \"/Users/moteroperdido/Desktop/projects/the_neural_maze/projects/multimodal-agents-course/.venv/lib/python3.12/site-packages/pixeltable/functions/openai.py\", line 447, in <lambda>\n    resource_pool, lambda: OpenAIRateLimitsInfo(_chat_completions_get_request_resources)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/moteroperdido/Desktop/projects/the_neural_maze/projects/multimodal-agents-course/.venv/lib/python3.12/site-packages/pixeltable/functions/openai.py\", line 96, in __init__\n    import openai\nModuleNotFoundError: No module named 'openai'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/moteroperdido/Desktop/projects/the_neural_maze/projects/multimodal-agents-course/.venv/lib/python3.12/site-packages/pixeltable/exec/expr_eval/expr_eval_node.py\", line 393, in _done_cb\n    t.result()\n  File \"/Users/moteroperdido/.local/share/uv/python/cpython-3.12.8-macos-aarch64-none/lib/python3.12/asyncio/futures.py\", line 202, in result\n    raise self._exception.with_traceback(self._exception_tb)\n  File \"/Users/moteroperdido/.local/share/uv/python/cpython-3.12.8-macos-aarch64-none/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n    result = coro.send(None)\n             ^^^^^^^^^^^^^^^\n  File \"/Users/moteroperdido/Desktop/projects/the_neural_maze/projects/multimodal-agents-course/.venv/lib/python3.12/site-packages/pixeltable/exec/expr_eval/schedulers.py\", line 90, in _main_loop\n    await self._exec(item.request, item.exec_ctx, item.num_retries, is_task=False)\n  File \"/Users/moteroperdido/Desktop/projects/the_neural_maze/projects/multimodal-agents-course/.venv/lib/python3.12/site-packages/pixeltable/exec/expr_eval/schedulers.py\", line 207, in _exec\n    assert self.pool_info is not None\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mError\u001b[39m                                     Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Chat with your agent\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m response = \u001b[43magent\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchat\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mHello, who are you?\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(response)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 171\u001b[39m, in \u001b[36mBaseAgent.chat\u001b[39m\u001b[34m(self, message, image)\u001b[39m\n\u001b[32m    159\u001b[39m \u001b[38;5;28mself\u001b[39m.memory.insert(\n\u001b[32m    160\u001b[39m     [\n\u001b[32m    161\u001b[39m         {\n\u001b[32m   (...)\u001b[39m\u001b[32m    167\u001b[39m     ]\n\u001b[32m    168\u001b[39m )\n\u001b[32m    170\u001b[39m \u001b[38;5;66;03m# Store user message in agent table (which triggers the chat pipeline)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m171\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43magent\u001b[49m\u001b[43m.\u001b[49m\u001b[43minsert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessage_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_message_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser_message\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtimestamp\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mnow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    177\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msystem_prompt\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msystem_prompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mimage\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    181\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    183\u001b[39m \u001b[38;5;66;03m# Get LLM's response from agent table\u001b[39;00m\n\u001b[32m    184\u001b[39m result = (\n\u001b[32m    185\u001b[39m     \u001b[38;5;28mself\u001b[39m.agent.select(\u001b[38;5;28mself\u001b[39m.agent.agent_response)\n\u001b[32m    186\u001b[39m     .where(\u001b[38;5;28mself\u001b[39m.agent.message_id == user_message_id)\n\u001b[32m    187\u001b[39m     .collect()\n\u001b[32m    188\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/projects/the_neural_maze/projects/multimodal-agents-course/.venv/lib/python3.12/site-packages/pixeltable/catalog/insertable_table.py:160\u001b[39m, in \u001b[36mInsertableTable.insert\u001b[39m\u001b[34m(self, source, source_format, schema_overrides, on_error, print_stats, **kwargs)\u001b[39m\n\u001b[32m    157\u001b[39m data_source.prepare_for_insert_into_table()\n\u001b[32m    159\u001b[39m fail_on_exception = OnErrorParameter.fail_on_exception(on_error)\n\u001b[32m--> \u001b[39m\u001b[32m160\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtable\u001b[49m\u001b[43m.\u001b[49m\u001b[43minsert_table_data_source\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata_source\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata_source\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfail_on_exception\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfail_on_exception\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_stats\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprint_stats\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/projects/the_neural_maze/projects/multimodal-agents-course/.venv/lib/python3.12/site-packages/pixeltable/catalog/insertable_table.py:178\u001b[39m, in \u001b[36mInsertableTable.insert_table_data_source\u001b[39m\u001b[34m(self, data_source, fail_on_exception, print_stats)\u001b[39m\n\u001b[32m    176\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    177\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m row_batch \u001b[38;5;129;01min\u001b[39;00m data_source.valid_row_batch():\n\u001b[32m--> \u001b[39m\u001b[32m178\u001b[39m             status += \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_tbl_version\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43minsert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrows\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrow_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_stats\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprint_stats\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfail_on_exception\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfail_on_exception\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    182\u001b[39m Env.get().console_logger.info(status.insert_msg)\n\u001b[32m    184\u001b[39m FileCache.get().emit_eviction_warnings()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/projects/the_neural_maze/projects/multimodal-agents-course/.venv/lib/python3.12/site-packages/pixeltable/catalog/table_version.py:834\u001b[39m, in \u001b[36mTableVersion.insert\u001b[39m\u001b[34m(self, rows, df, print_stats, fail_on_exception)\u001b[39m\n\u001b[32m    831\u001b[39m         \u001b[38;5;28mself\u001b[39m.next_rowid += \u001b[32m1\u001b[39m\n\u001b[32m    832\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m rowid\n\u001b[32m--> \u001b[39m\u001b[32m834\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_insert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mplan\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtime\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_stats\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprint_stats\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrowids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrowids\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mabort_on_exc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfail_on_exception\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/projects/the_neural_maze/projects/multimodal-agents-course/.venv/lib/python3.12/site-packages/pixeltable/catalog/table_version.py:849\u001b[39m, in \u001b[36mTableVersion._insert\u001b[39m\u001b[34m(self, exec_plan, timestamp, rowids, print_stats, abort_on_exc)\u001b[39m\n\u001b[32m    847\u001b[39m \u001b[38;5;28mself\u001b[39m.version += \u001b[32m1\u001b[39m\n\u001b[32m    848\u001b[39m result = UpdateStatus()\n\u001b[32m--> \u001b[39m\u001b[32m849\u001b[39m num_rows, num_excs, cols_with_excs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstore_tbl\u001b[49m\u001b[43m.\u001b[49m\u001b[43minsert_rows\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    850\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexec_plan\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv_min\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mversion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrowids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrowids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mabort_on_exc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mabort_on_exc\u001b[49m\n\u001b[32m    851\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    852\u001b[39m result.num_rows = num_rows\n\u001b[32m    853\u001b[39m result.num_excs = num_excs\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/projects/the_neural_maze/projects/multimodal-agents-course/.venv/lib/python3.12/site-packages/pixeltable/store.py:337\u001b[39m, in \u001b[36mStoreBase.insert_rows\u001b[39m\u001b[34m(self, exec_plan, v_min, show_progress, rowids, abort_on_exc)\u001b[39m\n\u001b[32m    335\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    336\u001b[39m     exec_plan.open()\n\u001b[32m--> \u001b[39m\u001b[32m337\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrow_batch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mexec_plan\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    338\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnum_rows\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mrow_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    339\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_start_idx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mrow_batch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__INSERT_BATCH_SIZE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    340\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# compute batch of rows and convert them into table rows\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/projects/the_neural_maze/projects/multimodal-agents-course/.venv/lib/python3.12/site-packages/pixeltable/exec/exec_node.py:83\u001b[39m, in \u001b[36mExecNode.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     81\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     82\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m83\u001b[39m         batch: DataRowBatch = \u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_until_complete\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43maiter\u001b[39;49m\u001b[43m.\u001b[49m\u001b[34;43m__anext__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     84\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m batch\n\u001b[32m     85\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopAsyncIteration\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/projects/the_neural_maze/projects/multimodal-agents-course/.venv/lib/python3.12/site-packages/nest_asyncio.py:98\u001b[39m, in \u001b[36m_patch_loop.<locals>.run_until_complete\u001b[39m\u001b[34m(self, future)\u001b[39m\n\u001b[32m     95\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m f.done():\n\u001b[32m     96\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m     97\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mEvent loop stopped before Future completed.\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m98\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.12.8-macos-aarch64-none/lib/python3.12/asyncio/futures.py:202\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    200\u001b[39m \u001b[38;5;28mself\u001b[39m.__log_traceback = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    201\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m202\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception.with_traceback(\u001b[38;5;28mself\u001b[39m._exception_tb)\n\u001b[32m    203\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.12.8-macos-aarch64-none/lib/python3.12/asyncio/tasks.py:314\u001b[39m, in \u001b[36mTask.__step_run_and_handle_result\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m    310\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    311\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    312\u001b[39m         \u001b[38;5;66;03m# We use the `send` method directly, because coroutines\u001b[39;00m\n\u001b[32m    313\u001b[39m         \u001b[38;5;66;03m# don't have `__iter__` and `__next__` methods.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m314\u001b[39m         result = \u001b[43mcoro\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    315\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    316\u001b[39m         result = coro.throw(exc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/projects/the_neural_maze/projects/multimodal-agents-course/.venv/lib/python3.12/site-packages/pixeltable/exec/expr_eval/expr_eval_node.py:289\u001b[39m, in \u001b[36mExprEvalNode.__aiter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    287\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m.error \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mself\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01merror\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexc\u001b[39;00m\n\u001b[32m    288\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m289\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m.error\n\u001b[32m    290\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m completed_aw \u001b[38;5;129;01min\u001b[39;00m done:\n\u001b[32m    291\u001b[39m     \u001b[38;5;28mself\u001b[39m._log_state(\u001b[33m'\u001b[39m\u001b[33mcompleted_aw done\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mError\u001b[39m: Exception in task: \nTraceback (most recent call last):\n  File \"/Users/moteroperdido/Desktop/projects/the_neural_maze/projects/multimodal-agents-course/.venv/lib/python3.12/site-packages/pixeltable/exec/expr_eval/schedulers.py\", line 190, in _exec\n    result = await pxt_fn.aexec(*request.args, **request.kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/moteroperdido/Desktop/projects/the_neural_maze/projects/multimodal-agents-course/.venv/lib/python3.12/site-packages/pixeltable/func/callable_function.py\", line 84, in aexec\n    return await self.py_fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/moteroperdido/Desktop/projects/the_neural_maze/projects/multimodal-agents-course/.venv/lib/python3.12/site-packages/pixeltable/functions/openai.py\", line 446, in chat_completions\n    rate_limits_info = env.Env.get().get_resource_pool_info(\n                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/moteroperdido/Desktop/projects/the_neural_maze/projects/multimodal-agents-course/.venv/lib/python3.12/site-packages/pixeltable/env.py\", line 705, in get_resource_pool_info\n    info = make_pool_info()\n           ^^^^^^^^^^^^^^^^\n  File \"/Users/moteroperdido/Desktop/projects/the_neural_maze/projects/multimodal-agents-course/.venv/lib/python3.12/site-packages/pixeltable/functions/openai.py\", line 447, in <lambda>\n    resource_pool, lambda: OpenAIRateLimitsInfo(_chat_completions_get_request_resources)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/moteroperdido/Desktop/projects/the_neural_maze/projects/multimodal-agents-course/.venv/lib/python3.12/site-packages/pixeltable/functions/openai.py\", line 96, in __init__\n    import openai\nModuleNotFoundError: No module named 'openai'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/moteroperdido/Desktop/projects/the_neural_maze/projects/multimodal-agents-course/.venv/lib/python3.12/site-packages/pixeltable/exec/expr_eval/expr_eval_node.py\", line 393, in _done_cb\n    t.result()\n  File \"/Users/moteroperdido/.local/share/uv/python/cpython-3.12.8-macos-aarch64-none/lib/python3.12/asyncio/futures.py\", line 202, in result\n    raise self._exception.with_traceback(self._exception_tb)\n  File \"/Users/moteroperdido/.local/share/uv/python/cpython-3.12.8-macos-aarch64-none/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n    result = coro.send(None)\n             ^^^^^^^^^^^^^^^\n  File \"/Users/moteroperdido/Desktop/projects/the_neural_maze/projects/multimodal-agents-course/.venv/lib/python3.12/site-packages/pixeltable/exec/expr_eval/schedulers.py\", line 90, in _main_loop\n    await self._exec(item.request, item.exec_ctx, item.num_retries, is_task=False)\n  File \"/Users/moteroperdido/Desktop/projects/the_neural_maze/projects/multimodal-agents-course/.venv/lib/python3.12/site-packages/pixeltable/exec/expr_eval/schedulers.py\", line 207, in _exec\n    assert self.pool_info is not None\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError\n"
     ]
    }
   ],
   "source": [
    "# Chat with your agent\n",
    "response = agent.chat(\"Hello, who are you?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserting rows into `memory`: 1 rows [00:00, 786.04 rows/s]\n",
      "Inserted 1 row with 0 errors.\n",
      "Inserting rows into `agent`: 1 rows [00:00, 260.14 rows/s]\n",
      "Inserted 1 row with 0 errors.\n",
      "Inserting rows into `memory`: 1 rows [00:00, 595.61 rows/s]\n",
      "Inserted 1 row with 0 errors.\n",
      "Yes, you mentioned that your name is Miguel. How can I help you today, Miguel?\n"
     ]
    }
   ],
   "source": [
    "from pixelagent.openai import Agent  # Or from pixelagent.openai import Agent\n",
    "\n",
    "# Create a simple agent\n",
    "agent = Agent(\n",
    "    name=\"my_assistant\",\n",
    "    system_prompt=\"You are a helpful assistant.\",\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Chat with your agent\n",
    "response = agent.chat(\"Do you know my name?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
