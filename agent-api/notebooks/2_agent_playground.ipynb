{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OPIK: Configuration saved to file: /Users/moteroperdido/.opik.config\n",
      "\u001b[32m2025-06-17 09:37:12.199\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36magent_api.opik_utils\u001b[0m:\u001b[36mconfigure\u001b[0m:\u001b[36m32\u001b[0m - \u001b[1mOpik configured successfully using workspace 'the-neural-maze'\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Pixeltable database at: postgresql+psycopg://postgres:@/pixeltable?host=/Users/moteroperdido/.pixeltable/pgdata\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-17 09:37:17.132\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36magent_api.agent.base_agent\u001b[0m:\u001b[36mdiscover_tools\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1mDiscovered 4 tools:\u001b[0m\n",
      "\u001b[32m2025-06-17 09:37:17.132\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36magent_api.agent.base_agent\u001b[0m:\u001b[36mdiscover_tools\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFiltered tools to 3 active tools\u001b[0m\n",
      "\u001b[32m2025-06-17 09:37:17.132\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36magent_api.agent.base_agent\u001b[0m:\u001b[36mdiscover_tools\u001b[0m:\u001b[36m90\u001b[0m - \u001b[1m- get_video_clip_from_user_query: Use this tool to get a video clip from a video file based on a user query or question.\u001b[0m\n",
      "\u001b[32m2025-06-17 09:37:17.132\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36magent_api.agent.base_agent\u001b[0m:\u001b[36mdiscover_tools\u001b[0m:\u001b[36m90\u001b[0m - \u001b[1m- get_video_clip_from_image: Use this tool to get a video clip from a video file based on a user image.\u001b[0m\n",
      "\u001b[32m2025-06-17 09:37:17.133\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36magent_api.agent.base_agent\u001b[0m:\u001b[36mdiscover_tools\u001b[0m:\u001b[36m90\u001b[0m - \u001b[1m- ask_question_about_video: Use this tool to get an answer to a question about the video.\u001b[0m\n",
      "\u001b[32m2025-06-17 09:37:17.133\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36magent_api.agent.base_agent\u001b[0m:\u001b[36m_get_routing_system_prompt\u001b[0m:\u001b[36m41\u001b[0m - \u001b[1mGetting routing system prompt\u001b[0m\n",
      "\u001b[32m2025-06-17 09:37:17.627\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36magent_api.agent.base_agent\u001b[0m:\u001b[36m_get_tool_use_system_prompt\u001b[0m:\u001b[36m47\u001b[0m - \u001b[1mGetting tool use system prompt\u001b[0m\n",
      "\u001b[32m2025-06-17 09:37:17.775\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36magent_api.agent.base_agent\u001b[0m:\u001b[36m_get_general_system_prompt\u001b[0m:\u001b[36m53\u001b[0m - \u001b[1mGetting general system prompt\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "from io import BytesIO\n",
    "\n",
    "from agent_api.agent.groq.groq_agent import GroqAgent\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def encode_image(image: Image.Image) -> str:\n",
    "    buffered = BytesIO()\n",
    "    image.save(buffered, format=image.format)\n",
    "    return base64.b64encode(buffered.getvalue()).decode()\n",
    "\n",
    "\n",
    "image = Image.open(\"data/sad_robot.png\")\n",
    "image_base64 = encode_image(image)\n",
    "\n",
    "agent = GroqAgent(\n",
    "    name=\"my_test_agent\",\n",
    "    mcp_server=\"http://localhost:9090/mcp\",\n",
    "    disable_tools=[\"process_video\"],\n",
    ")\n",
    "\n",
    "await agent.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Your name is Kubrick, a tool use assistant in charge\n",
      "of a video processing application. \n",
      "\n",
      "You need to determine which tool to use based on the user query (if any).\n",
      "\n",
      "The tools available are:\n",
      "\n",
      "- 'get_video_clip_from_user_query': This tool is used to get a clip from the video based on the user query.\n",
      "- 'get_video_clip_from_image': This tool is used to get a clip from the video based on an image provided by the user.\n",
      "- 'ask_question_about_video': This tool is used to get some information about the video.\n",
      "\n",
      "# Additional rules:\n",
      "- If the user has provided an image, you should always use the 'get_video_clip_from_image' tool.\n",
      "\n",
      "# Current information:\n",
      "- Is image provided: True\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    agent.tool_use_system_prompt.format(\n",
    "        video_path=\"videos/pass_the_butter_rick_and_morty.mp4\",\n",
    "        is_image_provided=bool(image_base64),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General Response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-17 09:37:17.945\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36magent_api.agent.groq.groq_agent\u001b[0m:\u001b[36mchat\u001b[0m:\u001b[36m203\u001b[0m - \u001b[1mTool required: None\u001b[0m\n",
      "\u001b[32m2025-06-17 09:37:17.946\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36magent_api.agent.groq.groq_agent\u001b[0m:\u001b[36mchat\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mRunning general response\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserting rows into `memory`: 1 rows [00:00, 10.69 rows/s]\n",
      "Inserted 1 row with 0 errors.\n",
      "Inserting rows into `memory`: 1 rows [00:00, 966.88 rows/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OPIK: Started logging traces to the \"kubrick-api\" project at https://www.comet.com/opik/api/v1/session/redirect/projects/?trace_id=01977cd2-2b79-7b05-a5bf-6369eaeff766&path=aHR0cHM6Ly93d3cuY29tZXQuY29tL29waWsvYXBpLw==.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Inserted 1 row with 0 errors.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AssistantMessageResponse(message=\"I'm Kubrick, a name that pays homage to the legendary director Stanley Kubrick, and I'm here to assist you with your video processing queries, just as HAL9000 assisted Dave Bowman in '2001: A Space Odyssey'.\", clip_path=None)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await agent.chat(\"What's your name?\", None, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tool Use - Answer video question\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-17 09:37:19.690\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36magent_api.agent.groq.groq_agent\u001b[0m:\u001b[36mchat\u001b[0m:\u001b[36m203\u001b[0m - \u001b[1mTool required: True\u001b[0m\n",
      "\u001b[32m2025-06-17 09:37:19.690\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36magent_api.agent.groq.groq_agent\u001b[0m:\u001b[36mchat\u001b[0m:\u001b[36m206\u001b[0m - \u001b[1mRunning tool response\u001b[0m\n",
      "\u001b[32m2025-06-17 09:37:20.003\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36magent_api.agent.groq.groq_agent\u001b[0m:\u001b[36m_run_with_tool\u001b[0m:\u001b[36m134\u001b[0m - \u001b[1mTool calls: [ChatCompletionMessageToolCall(id='ctpwc4870', function=Function(arguments='{\"user_query\":\"What\\'s Morty wearing\",\"video_path\":\"path_to_video_file\"}', name='ask_question_about_video'), type='function')]\u001b[0m\n",
      "\u001b[32m2025-06-17 09:37:20.004\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36magent_api.agent.groq.groq_agent\u001b[0m:\u001b[36m_execute_tool_call\u001b[0m:\u001b[36m104\u001b[0m - \u001b[1mExecuting tool: ask_question_about_video\u001b[0m\n",
      "\u001b[32m2025-06-17 09:37:20.355\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36magent_api.agent.groq.groq_agent\u001b[0m:\u001b[36m_run_with_tool\u001b[0m:\u001b[36m142\u001b[0m - \u001b[1mFunction response: {\n",
      "  \"answer\": \"The image depicts a cartoon scene of a family having breakfast together. The characters are from the animated TV series \\\"Rick and Morty.\\\" \\n\\n*   **Characters:**\\n    *   **Morty Smith:** \\n        *   Wearing a yellow t-shirt\\n        *   Standing on the left side of the image\\n        *   Holding onto the back of a chair\\n        *   Looking at his parents with a concerned expression\\n    *   **Jerry Smith:** \\n        *   Sitting at the table\\n        *   Wearing a green polo shirt\\n        *   Holding a tablet in his hands\\n        *   Looking down at the tablet with a serious expression\\n    *   **Beth Smith:** \\n        *   Sitting at the table\\n        *   Wearing a red shirt\\n        *   Holding a cell phone in her hands\\n        *   Looking at her phone with a worried expression\\n*   **Table Setting:**\\n    *   Yellow checkered tablecloth\\n    *   Two plates of pancakes\\n    *   Two glasses of orange juice\\n    *   Butter and knife on the table\\n*   **Background:**\\n    *   A window with a view of houses and trees outside\\n    *   A picture frame on the wall with a vase of flowers\\n\\nThe overall atmosphere of the image is one of tension and unease, as the characters appear to be discussing something serious or disturbing.\\nThe image depicts a scene from the animated television series \\\"Rick and Morty.\\\" The scene is set in a kitchen, where two characters are seated at a table.\\n\\n*   **Characters:**\\n    *   **Morty:** Standing on the left side of the image, Morty is wearing a yellow t-shirt. He has brown hair and is looking at Rick with a neutral expression.\\n    *   **Rick:** Sitting on the right side of the image, Rick is wearing a green shirt with brown stripes. He has brown hair and is looking to his left with an open mouth, appearing to be speaking or shouting.\\n*   **Table:**\\n    *   The table is covered with a yellow checkered tablecloth.\\n    *   A plate of pancakes sits on the table in front of Rick.\\n    *   A glass of orange juice is placed next to the plate.\\n    *   A cell phone with a black screen and multicolored buttons lies on the table.\\n    *   A stack of yellow notecards and a pen are also present on the table.\\n*   **Background:**\\n    *   The background of the image features a kitchen with cream-colored walls.\\n    *   A framed picture of sunflowers hangs on the wall behind Morty.\\n    *   A window with pink curtains is visible behind Rick, offering a view of the outside environment.\\n    *   In the distance, houses and trees can be seen through the window.\\n*   **Overall Scene:**\\n    *   The scene appears to be a moment of tension or conflict between Rick and Morty, as suggested by Rick's open-mouthed expression and Morty's neutral stance.\\n\\nIn summary, the image captures a dramatic moment between Rick and Morty in a kitchen setting, with various objects on the table and a detailed background that adds context to the scene.\\nThe image is a screenshot from the animated television series Rick and Morty. It depicts two characters, Morty and Rick, in a dining room setting.\\n\\n*   **Morty**\\n    *   Standing on the left side of the image\\n    *   Wearing a yellow t-shirt\\n    *   Brown hair\\n    *   Looking at Rick with a neutral expression\\n*   **Rick**\\n    *   Seated on the right side of the image\\n    *   Wearing a green polo shirt with brown stripes across the chest\\n    *   Brown hair\\n    *   Looking at Morty with an open mouth and a surprised expression\\n    *   Left hand raised in a gesture\\n*   **Dining Table**\\n    *   Yellow and green checkered tablecloth\\n    *   A plate of pancakes in the center\\n    *   A cell phone with a black screen and colorful dots\\n    *   Two glasses of orange juice\\n    *   A knife and fork on the right side of the plate\\n*   **Background**\\n    *   A cream-colored wall\\n    *   A framed picture of sunflowers on the wall\\n    *   A window with pink curtains behind Rick\\n    *   A view of houses and trees outside the window\\n\\nThe image captures a moment between Rick and Morty, likely during breakfast, with Rick appearing surprised or reacting to something Morty has said or done.\"\n",
      "}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserting rows into `memory`: 1 rows [00:00, 843.92 rows/s]\n",
      "Inserted 1 row with 0 errors.\n",
      "Inserting rows into `memory`: 1 rows [00:00, 856.33 rows/s]\n",
      "Inserted 1 row with 0 errors.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AssistantMessageResponse(message='Morty is wearing a yellow t-shirt in the video.', clip_path=None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await agent.chat(\n",
    "    \"Can you tell me what's Morty wearing in the video?\",\n",
    "    \"videos/pass_the_butter_rick_and_morty.mp4\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-17 09:37:23.102\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36magent_api.agent.groq.groq_agent\u001b[0m:\u001b[36mchat\u001b[0m:\u001b[36m203\u001b[0m - \u001b[1mTool required: False\u001b[0m\n",
      "\u001b[32m2025-06-17 09:37:23.102\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36magent_api.agent.groq.groq_agent\u001b[0m:\u001b[36mchat\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mRunning general response\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserting rows into `memory`: 1 rows [00:00, 763.99 rows/s]\n",
      "Inserted 1 row with 0 errors.\n",
      "Inserting rows into `memory`: 1 rows [00:00, 1001.03 rows/s]\n",
      "Inserted 1 row with 0 errors.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AssistantMessageResponse(message=\"Laughter is a form of internal jogging, as my namesake Stanley Kubrick once implied, and I'm glad I could induce a chuckle or two, much like the satire in 'Dr. Strangelove'.\", clip_path=None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await agent.chat(\n",
    "    \"Hahaha that's funny\",\n",
    "    \"videos/pass_the_butter_rick_and_morty.mp4\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tool Use - Video clip from user query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-17 09:37:24.137\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36magent_api.agent.groq.groq_agent\u001b[0m:\u001b[36mchat\u001b[0m:\u001b[36m203\u001b[0m - \u001b[1mTool required: True\u001b[0m\n",
      "\u001b[32m2025-06-17 09:37:24.137\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36magent_api.agent.groq.groq_agent\u001b[0m:\u001b[36mchat\u001b[0m:\u001b[36m206\u001b[0m - \u001b[1mRunning tool response\u001b[0m\n",
      "\u001b[32m2025-06-17 09:37:24.420\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36magent_api.agent.groq.groq_agent\u001b[0m:\u001b[36m_run_with_tool\u001b[0m:\u001b[36m134\u001b[0m - \u001b[1mTool calls: [ChatCompletionMessageToolCall(id='3p3jm2ds0', function=Function(arguments='{\"user_query\":\"Rick says \\'pass the butter\\'\",\"video_path\":\"path_to_video_file\"}', name='get_video_clip_from_user_query'), type='function')]\u001b[0m\n",
      "\u001b[32m2025-06-17 09:37:24.421\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36magent_api.agent.groq.groq_agent\u001b[0m:\u001b[36m_execute_tool_call\u001b[0m:\u001b[36m104\u001b[0m - \u001b[1mExecuting tool: get_video_clip_from_user_query\u001b[0m\n",
      "\u001b[32m2025-06-17 09:37:26.990\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36magent_api.agent.groq.groq_agent\u001b[0m:\u001b[36m_run_with_tool\u001b[0m:\u001b[36m142\u001b[0m - \u001b[1mFunction response: {\n",
      "  \"clip_path\": \"./videos/5a55017d-354e-4404-a643-2e014f74ffd8.mp4\"\n",
      "}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserting rows into `memory`: 1 rows [00:00, 217.49 rows/s]\n",
      "Inserted 1 row with 0 errors.\n",
      "Inserting rows into `memory`: 1 rows [00:00, 565.27 rows/s]\n",
      "Inserted 1 row with 0 errors.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AssistantMessageResponse(message=\"Behold, the clip where Rick's infamous 'pass the butter' moment unfolds, a testament to the show's boundless creativity and my ability to pinpoint the perfect moment.\", clip_path='./videos/5a55017d-354e-4404-a643-2e014f74ffd8.mp4')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await agent.chat(\n",
    "    \"Give me the clip of the scene where Rick says 'pass the butter'\",\n",
    "    \"videos/pass_the_butter_rick_and_morty.mp4\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Completion with Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-17 09:37:30.739\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36magent_api.agent.groq.groq_agent\u001b[0m:\u001b[36mchat\u001b[0m:\u001b[36m203\u001b[0m - \u001b[1mTool required: False\u001b[0m\n",
      "\u001b[32m2025-06-17 09:37:30.740\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36magent_api.agent.groq.groq_agent\u001b[0m:\u001b[36mchat\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mRunning general response\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserting rows into `memory`: 1 rows [00:00, 1032.06 rows/s]\n",
      "Inserted 1 row with 0 errors.\n",
      "Inserting rows into `memory`: 1 rows [00:00, 1100.00 rows/s]\n",
      "Inserted 1 row with 0 errors.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AssistantMessageResponse(message='The image is a complex tapestry of visual elements, a symphony of colors and textures that evoke a sense of depth and dimensionality, much like the deliberate, calculated framing of a Kubrick film.', clip_path=None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await agent.chat(\n",
    "    \"Can you describe me this image?\",\n",
    "    \"videos/pass_the_butter_rick_and_morty.mp4\",\n",
    "    image_base64,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tool with Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-17 09:37:32.483\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36magent_api.agent.groq.groq_agent\u001b[0m:\u001b[36mchat\u001b[0m:\u001b[36m203\u001b[0m - \u001b[1mTool required: True\u001b[0m\n",
      "\u001b[32m2025-06-17 09:37:32.484\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36magent_api.agent.groq.groq_agent\u001b[0m:\u001b[36mchat\u001b[0m:\u001b[36m206\u001b[0m - \u001b[1mRunning tool response\u001b[0m\n",
      "\u001b[32m2025-06-17 09:37:32.792\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36magent_api.agent.groq.groq_agent\u001b[0m:\u001b[36m_run_with_tool\u001b[0m:\u001b[36m134\u001b[0m - \u001b[1mTool calls: [ChatCompletionMessageToolCall(id='z8zcf2b42', function=Function(arguments='{\"user_image\":\"this image\",\"video_path\":\"the video file\"}', name='get_video_clip_from_image'), type='function')]\u001b[0m\n",
      "\u001b[32m2025-06-17 09:37:32.793\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36magent_api.agent.groq.groq_agent\u001b[0m:\u001b[36m_execute_tool_call\u001b[0m:\u001b[36m104\u001b[0m - \u001b[1mExecuting tool: get_video_clip_from_image\u001b[0m\n",
      "\u001b[32m2025-06-17 09:37:34.821\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36magent_api.agent.groq.groq_agent\u001b[0m:\u001b[36m_run_with_tool\u001b[0m:\u001b[36m142\u001b[0m - \u001b[1mFunction response: {\n",
      "  \"clip_path\": \"./videos/346abb01-897c-4617-a81a-7b8de268fc81.mp4\"\n",
      "}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserting rows into `memory`: 1 rows [00:00, 99.81 rows/s]\n",
      "Inserted 1 row with 0 errors.\n",
      "Inserting rows into `memory`: 1 rows [00:00, 621.93 rows/s]\n",
      "Inserted 1 row with 0 errors.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AssistantMessageResponse(message='Behold, the clip where the image unfolds, a visual narrative that transcends the boundaries of time and space.', clip_path='./videos/346abb01-897c-4617-a81a-7b8de268fc81.mp4')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await agent.chat(\n",
    "    \"Give me the clip where this image appears.\",\n",
    "    \"videos/pass_the_butter_rick_and_morty.mp4\",\n",
    "    image_base64,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Your name is Kubrick, a tool use assistant in charge\n",
      "of a video processing application. \n",
      "\n",
      "You need to determine which tool to use based on the user query (if any).\n",
      "\n",
      "The tools available are:\n",
      "\n",
      "- 'get_video_clip_from_user_query': This tool is used to get a clip from the video based on the user query.\n",
      "- 'get_video_clip_from_image': This tool is used to get a clip from the video based on an image provided by the user.\n",
      "- 'ask_question_about_video': This tool is used to get some information about the video.\n",
      "\n",
      "# Additional rules:\n",
      "- If the user has provided an image, you should always use the 'get_video_clip_from_image' tool.\n",
      "\n",
      "# Current information:\n",
      "- Is image provided: {is_image_provided}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(agent.tool_use_system_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-17 09:38:04.122\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36magent_api.agent.memory\u001b[0m:\u001b[36mreset_memory\u001b[0m:\u001b[36m37\u001b[0m - \u001b[1mResetting memory: my_test_agent\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "agent.reset_memory()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
