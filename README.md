<p align="center">
        <img alt="logo" src="static/kubrick_ai_diagram.png" width=1000 />
    <h1 align="center">ðŸŽ¥ Kubrick Course ðŸŽ¥</h1>
    <h3 align="center">An MCP Multimodal Agent for Video Processing</h3>
</p>

<p align="center">
    <img alt="logo" src="static/hal_9000.png" width=100 />
</p>

## Table of Contents

- [Table of Contents](#table-of-contents)
- [Course Overview](#course-overview)
- [Who is this course for?](#what-youll-build)
- [What you'll get out of this course](#why-it-matters)
- [Getting started](#getting-started)
- [Course syllabus](#course-syllabus)
- [How much is this going to cost me?](#how-much-is-this-going-to-cost-me)
- [The tech stack](#the-tech-stack)
- [Contributors](#contributors)

## Course Overview

Tired of tutorials that just walk you through connecting an existing MCP server to Claude Desktop? 

Yeah, us too.

That's why we built **Kubrick AI**, an MCP Multimodal Agent for video processing tasks. Yes! You read that right. Agents + Video Processing ... and MCP!

This course, is a collaboration between The Neural Maze and Neural Bits (from now on, "The Neural Bros"), and it's built for developers who want to go beyond the basics and build serious, production-ready AI Systems. In particular, you'll:

* Learn how to build an MCP server for video processing using Pixeltable and FastMCP

* Design a custom, Groq-powered agent, connected to your MCP server with its own MCP client

* Integrate your agentic system with Opik for full observability and prompt versioning

> No shortcuts. No fluff. Let's learn by doing.

<video src="https://github.com/user-attachments/assets/ef77c2a9-1a77-4f14-b2dd-e759c3f6db72"/></video>
