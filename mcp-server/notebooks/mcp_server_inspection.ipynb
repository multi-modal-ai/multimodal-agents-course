{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the MCP Server"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will play around with the MCP server, understanding the tools, resources and prompts it exposes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MCP Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastmcp import Client\n",
    "\n",
    "client = Client(\"http://127.0.0.1:8000/mcp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Listing every tool available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool name: process_video\n",
      "Tool description: Process a video file and prepare it for searching.\n",
      "Tool name: list_tables\n",
      "Tool description: List all processed videos in the database.\n",
      "Tool name: get_clip_by_speech_sim\n",
      "Tool description: Get a video clip based on a user query using the transcripts index.\n",
      "Tool name: get_clip_by_image_sim\n",
      "Tool description: Get a video clip based on a user query using the image index.\n",
      "Tool name: get_clip_by_caption_sim\n",
      "Tool description: Get a video clip based on a user query using the caption index.\n"
     ]
    }
   ],
   "source": [
    "async with client:\n",
    "    tools = await client.list_tools()\n",
    "    for tool in tools:\n",
    "        print(f\"Tool name: {tool.name}\")\n",
    "        print(f\"Tool description: {tool.description}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calling the tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we know what tools are available, we can call them manually. This is exactly what's going to happen when the agent is calling the tools from the Agentic API.\n",
    "\n",
    "The first tool we're going to call is the `process_video` tool. This tool is going to process a video and prepare it for searching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TextContent(type='text', text='Video processed successfully', annotations=None)]\n"
     ]
    }
   ],
   "source": [
    "async with client:\n",
    "    result = await client.call_tool(\n",
    "        \"process_video\", {\"video_path\": \"./videos/pass_the_butter_rick_and_morty.mp4\"}\n",
    "    )\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TextContent(type='text', text='Current video indexes: ./videos/pass_the_butter_rick_and_morty.mp4', annotations=None)]\n"
     ]
    }
   ],
   "source": [
    "async with client:\n",
    "    result = await client.call_tool(\"list_tables\")\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TextContent(type='text', text='[\\n  {\\n    \"start_time\": 32.04,\\n    \"end_time\": 37.0081,\\n    \"similarity\": 0.8820401359820839\\n  },\\n  {\\n    \"start_time\": 52.032,\\n    \"end_time\": 57.0001,\\n    \"similarity\": 0.8666490832954483\\n  },\\n  {\\n    \"start_time\": 36.024,\\n    \"end_time\": 41.0161,\\n    \"similarity\": 0.7982815859653684\\n  }\\n]', annotations=None)]\n"
     ]
    }
   ],
   "source": [
    "async with client:\n",
    "    result = await client.call_tool(\n",
    "        \"get_clip_by_speech_sim\",\n",
    "        {\n",
    "            \"video_name\": \"./videos/pass_the_butter_rick_and_morty.mp4\",\n",
    "            \"user_query\": \"Pass the butter\",\n",
    "        },\n",
    "    )\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextContent(type='text', text='[\\n  {\\n    \"start_time\": 32.04,\\n    \"end_time\": 37.0081,\\n    \"similarity\": 0.8820401359820839\\n  },\\n  {\\n    \"start_time\": 52.032,\\n    \"end_time\": 57.0001,\\n    \"similarity\": 0.8666490832954483\\n  },\\n  {\\n    \"start_time\": 36.024,\\n    \"end_time\": 41.0161,\\n    \"similarity\": 0.7982815859653684\\n  }\\n]', annotations=None)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mcp-server-venv",
   "language": "python",
   "name": "mcp-server-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
